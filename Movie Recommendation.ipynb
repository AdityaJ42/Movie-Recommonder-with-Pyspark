{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing RDD for movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_file_path = os.path.join(os.getcwd(), 'ml-latest-small', 'ratings.csv')\n",
    "ratings_raw_data = sc.textFile(ratings_file_path)\n",
    "ratings_header = ratings_raw_data.take(1)[0]\n",
    "ratings_data_RDD = ratings_raw_data.filter(lambda line: line != ratings_header).map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0], tokens[1], tokens[2])).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing RDD for movies list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_file_path = os.path.join(os.getcwd(), 'ml-latest-small', 'movies.csv')\n",
    "movies_raw_data = sc.textFile(movies_file_path)\n",
    "movies_header = movies_raw_data.take(1)[0]\n",
    "movies_data_RDD = movies_raw_data.filter(lambda line: line != movies_header).map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0], tokens[1])).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising ratings and movie RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId\tmovieId\trating\n",
      "1\t1\t4.0\n",
      "1\t3\t4.0\n",
      "1\t6\t4.0\n",
      "1\t47\t5.0\n",
      "1\t50\t5.0\n"
     ]
    }
   ],
   "source": [
    "print('\\t'.join(ratings_header.split(',')[:-1]))\n",
    "for i in ratings_data_RDD.take(5):\n",
    "    print('{}\\t{}\\t{}'.format(i[0], i[1], i[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId\ttitle\n",
      "1\tToy Story (1995)\n",
      "2\tJumanji (1995)\n",
      "3\tGrumpier Old Men (1995)\n",
      "4\tWaiting to Exhale (1995)\n",
      "5\tFather of the Bride Part II (1995)\n"
     ]
    }
   ],
   "source": [
    "print('\\t'.join(movies_header.split(',')[:-1]))\n",
    "for i in movies_data_RDD.take(5):\n",
    "    print('{}\\t{}'.format(i[0], i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting ratings RDD into training, testing and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, validation_RDD, testing_RDD = ratings_data_RDD.randomSplit([0.6, 0.2, 0.2])\n",
    "validation_predict_RDD = validation_RDD.map(lambda r: (r[0], r[1]))\n",
    "testing_predict_RDD = testing_RDD.map(lambda r: (r[0], r[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training RDD: 60438\n",
      "Size of validation RDD: 20198\n",
      "Size of testing RDD: 20200\n"
     ]
    }
   ],
   "source": [
    "print('Size of training RDD: {}'.format(training_RDD.count()))\n",
    "print('Size of validation RDD: {}'.format(validation_RDD.count()))\n",
    "print('Size of testing RDD: {}'.format(testing_RDD.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best rank for ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 4\tRMSE Error: 0.9218659169501069\n",
      "Rank: 8\tRMSE Error: 0.9160156470726885\n",
      "Rank: 12\tRMSE Error: 0.9241499515046814\n",
      "-------------------------\n",
      "Best Rank: 8\n"
     ]
    }
   ],
   "source": [
    "seed, iterations, lr = 5, 10, 0.1\n",
    "errors, err, min_error = [0, 0, 0], 0, float('inf')\n",
    "ranks, best_rank = [4, 8, 12], -1\n",
    "\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations, lambda_=lr)\n",
    "    predictions = model.predictAll(validation_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    ratings_and_predictions = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(ratings_and_predictions.map(lambda r: (r[1][0] - r[1][1]) ** 2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    if error < min_error:\n",
    "        best_rank, min_error = rank, error\n",
    "    print('Rank: {}\\tRMSE Error: {}'.format(rank, error))\n",
    "print('-' * 25)\n",
    "print('Best Rank: {}'.format(best_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing predictions results and comparison with actual ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId\tmovieId\tPredicted Rating\n",
      "140\t1084\t4.01\n",
      "32\t1084\t4.51\n",
      "309\t1084\t4.09\n",
      "177\t1084\t3.79\n",
      "474\t1084\t3.77\n"
     ]
    }
   ],
   "source": [
    "print('userId\\tmovieId\\tPredicted Rating')\n",
    "for i in predictions.take(5):\n",
    "    print('{}\\t{}\\t{}'.format(i[0][0], i[0][1], round(i[1], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId\tmovieId\tActual Rating\tPredicted Rating\n",
      "1\t47\t5.0\t\t4.66\n",
      "1\t367\t4.0\t\t3.32\n",
      "1\t457\t5.0\t\t4.88\n",
      "1\t1625\t5.0\t\t4.32\n",
      "1\t2137\t5.0\t\t4.55\n"
     ]
    }
   ],
   "source": [
    "print('userId\\tmovieId\\tActual Rating\\tPredicted Rating')\n",
    "for i in ratings_and_predictions.take(5):\n",
    "    print('{}\\t{}\\t{}\\t\\t{}'.format(i[0][0], i[0][1], i[1][0], round(i[1][1], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on test set: 0.9099272124697338\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations, lambda_=lr)\n",
    "predictions = model.predictAll(testing_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratings_and_predictions = testing_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(ratings_and_predictions.map(lambda r: (r[1][0] - r[1][1]) ** 2).mean())\n",
    "print('Error on test set: {}'.format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data and restructuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_file_path = os.path.join(os.getcwd(), 'ml-latest-small', 'ratings.csv')\n",
    "ratings_raw_data = sc.textFile(ratings_file_path)\n",
    "ratings_header = ratings_raw_data.take(1)[0]\n",
    "complete_ratings_data = ratings_raw_data.filter(lambda line: line != ratings_header).map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]), int(tokens[1]), float(tokens[2]))).cache()\n",
    "\n",
    "movies_file_path = os.path.join(os.getcwd(), 'ml-latest-small', 'movies.csv')\n",
    "movies_raw_data = sc.textFile(movies_file_path)\n",
    "movies_header = movies_raw_data.take(1)[0]\n",
    "complete_movies_data = movies_raw_data.filter(lambda line: line != movies_header).map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]), tokens[1], tokens[2])).cache()\n",
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting ratings for each movie and finding average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_and_averages(id_and_rating_tuple):\n",
    "    n = len(id_and_rating_tuple[1])\n",
    "    return id_and_rating_tuple[0], (n, float(sum(x for x in id_and_rating_tuple[1])) / n)\n",
    "\n",
    "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId\tNo of Reviews\tAvg Rating\n",
      "6\t102\t\t3.95\n",
      "50\t204\t\t4.24\n",
      "70\t55\t\t3.51\n",
      "110\t237\t\t4.03\n",
      "216\t49\t\t3.33\n"
     ]
    }
   ],
   "source": [
    "print('movieId\\tNo of Reviews\\tAvg Rating')\n",
    "for i in movie_ID_with_avg_ratings_RDD.take(5):\n",
    "    print('{}\\t{}\\t\\t{}'.format(i[0], i[1][0], round(i[1][1], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new user to make recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id = 0\n",
    "new_user_ratings = [\n",
    "    (0,260,4),\n",
    "    (0,1,3),\n",
    "    (0,16,3),\n",
    "    (0,25,4),\n",
    "    (0,32,4),\n",
    "    (0,335,1),\n",
    "    (0,379,1),\n",
    "    (0,296,3),\n",
    "    (0,858,5),\n",
    "    (0,50,4)\n",
    "]\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging new user data with existing data and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)\n",
    "new_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, iterations=iterations, lambda_=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_id, x[0])))\n",
    "new_user_recommendations_RDD = new_model.predictAll(new_user_unrated_movies_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD = new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 Movies According To User Preferences:\n",
      "--------------------------------------------------\n",
      "Killing Fields\n",
      "Producers\n",
      "Godfather\n",
      "Citizen Kane (1941)\n",
      "Monty Python and the Holy Grail (1975)\n",
      "North by Northwest (1959)\n",
      "Philadelphia Story\n",
      "Godfather: Part II\n",
      "12 Angry Men (1957)\n",
      "Big Lebowski\n",
      "Bridge on the River Kwai\n",
      "Chinatown (1974)\n",
      "Fargo (1996)\n",
      "Casablanca (1942)\n",
      "Schindler's List (1993)\n",
      "Great Escape\n",
      "Lawrence of Arabia (1962)\n",
      "Apocalypse Now (1979)\n",
      "Strangers on a Train (1951)\n",
      "Raging Bull (1980)\n",
      "Boot\n",
      "Wallace & Gromit: The Best of Aardman Animation (1996)\n",
      "Cool Hand Luke (1967)\n",
      "Hoop Dreams (1994)\n",
      "Election (1999)\n"
     ]
    }
   ],
   "source": [
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n",
    "print('Top 25 Movies According To User Preferences:')\n",
    "print('-' * 50)\n",
    "for movie in top_movies:\n",
    "    print(movie[0].replace('\"', ''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
